{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc087f3",
   "metadata": {},
   "source": [
    "## MCP ##\n",
    "\n",
    "How LLM get access to context (tools and resources)\n",
    "MCP client host in the LLM app and MCP server (tool, data resources, prompt template)\n",
    "\n",
    "REST APIs: Standardize how web apps interact with the backend\n",
    "LSP: Standardize how IDEs interact with language-specific tools\n",
    "MCP: Standardize how AI apps interact with external systems\n",
    "\n",
    "# Communication Lifecycle\n",
    "MCP Client <------> MCP Sever\n",
    "1. Initialization (init request, init response, init notification)\n",
    "2. Message Exchange (request, response, notification)\n",
    "3. Termination\n",
    "\n",
    "MCP Transport: Handles the underlying mechs of how messages are sent back & fort\n",
    "1. stdio (standard input output): local severs\n",
    "2. HTTP+SSE and Streamable HTTP: for remote severs ( needs stateful connection for HTTP+SSE while Streamable HTTP allows both stateful and stateless connection)\n",
    "\n",
    "-> Streambale HTTP\n",
    "    POST /mcp to initialize request\n",
    "    GET /mcp with Accept: text/event-stream   sever can send request to client\n",
    "    DELETE /mcp to terminate session\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9accbcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import anthropic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f583d1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_DIR = \"papers\"\n",
    "\n",
    "'''\n",
    "search for relevant papers on arxiv based on a topic\n",
    "store the paper info in a JSON file: title, authors, summary, and link\n",
    "'''\n",
    "\n",
    "def search_paper(topic:str, max_results:int=5) -> List[str]:\n",
    "    client = arxiv.Client()\n",
    "    search = arxiv.Search(\n",
    "        query=topic,\n",
    "        max_results=max_results,\n",
    "        sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(' ', '_'))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            \"title\": paper.title,\n",
    "            \"authors\": [author.name for author in paper.authors],\n",
    "            \"summary\": paper.summary,\n",
    "            \"pdf_url\": paper.pdf_url,\n",
    "            \"published\": str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "    print(f\"Saved paper info to: {file_path}\")        \n",
    "    \n",
    "    return paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fe6c02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved paper info to: papers\\machine_learning\\papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1909.03550v1',\n",
       " '1811.04422v1',\n",
       " '1707.04849v1',\n",
       " '1909.09246v1',\n",
       " '2301.09753v1']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_paper(\"machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "052de76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(paper_id: str) -> str:\n",
    "    ''' \n",
    "    search for information about a paper across all topic directories in the PAPER_DIR\n",
    "    '''\n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.exists(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "                    continue\n",
    "    return f\"Paper with ID {paper_id} not found in any topic directory.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31ead60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"title\": \"Lecture Notes: Optimization for Machine Learning\",\\n  \"authors\": [\\n    \"Elad Hazan\"\\n  ],\\n  \"summary\": \"Lecture notes on optimization for machine learning, derived from a course at\\\\nPrinceton University and tutorials given in MLSS, Buenos Aires, as well as\\\\nSimons Foundation, Berkeley.\",\\n  \"pdf_url\": \"http://arxiv.org/pdf/1909.03550v1\",\\n  \"published\": \"2019-09-08\"\\n}'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_info('1909.03550v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e005952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97463a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract_pdf_text(pdf_url: str) -> str:\n",
    "    \"\"\"\n",
    "    Download a PDF from a URL and extract its text content\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Download the PDF\n",
    "        response = requests.get(pdf_url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Read PDF content\n",
    "        pdf_file = BytesIO(response.content)\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        \n",
    "        # Extract text from all pages\n",
    "        text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "        \n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error downloading or extracting PDF: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2280da04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_paper(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Get comprehensive summary of a paper including abstract, problem statement, \n",
    "    methodology, existing solutions, improvements, results, and key findings\n",
    "    \"\"\"\n",
    "    # First get the paper info\n",
    "    paper_info = None\n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.exists(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, 'r') as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            paper_info = papers_info[paper_id]\n",
    "                            break\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    continue\n",
    "    \n",
    "    if not paper_info:\n",
    "        return f\"Paper with ID {paper_id} not found in any topic directory.\"\n",
    "    \n",
    "    # Extract PDF text\n",
    "    pdf_text = download_and_extract_pdf_text(paper_info['pdf_url'])\n",
    "    \n",
    "    if pdf_text.startswith(\"Error\"):\n",
    "        return f\"Could not download PDF: {pdf_text}\"\n",
    "    \n",
    "    # Prepare the prompt for Claude\n",
    "    prompt = f\"\"\"\n",
    "    Please provide a comprehensive summary of this research paper with the following structure:\n",
    "\n",
    "    **Paper Title:** {paper_info['title']}\n",
    "    **Authors:** {', '.join(paper_info['authors'])}\n",
    "    **Published:** {paper_info['published']}\n",
    "\n",
    "    Based on the full paper text below, please extract and summarize:\n",
    "\n",
    "    1. **Abstract/Summary:** Brief overview of the paper\n",
    "    2. **Problem Statement:** What problem are they trying to solve?\n",
    "    3. **Methodology/Framework:** What methods, techniques, or frameworks do they use?\n",
    "    4. **Existing Solutions:** What previous work exists in this area? What are the limitations of existing approaches?\n",
    "    5. **Proposed Improvements:** How does their approach improve upon existing solutions?\n",
    "    6. **Results:** What are the main experimental results and findings?\n",
    "    7. **Key Contributions:** What are the most important contributions and insights?\n",
    "    8. **Limitations:** What are the acknowledged limitations or potential weaknesses?\n",
    "\n",
    "    Full Paper Text:\n",
    "    {pdf_text[:15000]}  # Limit text to avoid token limits\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.messages.create(\n",
    "            max_tokens=3000,\n",
    "            model='claude-3-5-sonnet-20241022',\n",
    "            messages=[{'role': 'user', 'content': prompt}]\n",
    "        )\n",
    "        \n",
    "        return response.content[0].text\n",
    "    except Exception as e:\n",
    "        return f\"Error generating summary: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fa4c5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_papers_by_topic(topic: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyze all papers in a topic directory and provide comparative insights\n",
    "    \"\"\"\n",
    "    topic_dir = topic.lower().replace(' ', '_')\n",
    "    topic_path = os.path.join(PAPER_DIR, topic_dir)\n",
    "    \n",
    "    if not os.path.exists(topic_path):\n",
    "        return f\"No papers found for topic: {topic}\"\n",
    "    \n",
    "    file_path = os.path.join(topic_path, \"papers_info.json\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        return f\"No papers data found for topic: {topic}\"\n",
    "    \n",
    "    if not papers_info:\n",
    "        return f\"No papers found for topic: {topic}\"\n",
    "    \n",
    "    # Create a summary of all papers\n",
    "    papers_summary = []\n",
    "    for paper_id, info in papers_info.items():\n",
    "        papers_summary.append(f\"\"\"\n",
    "        Paper ID: {paper_id}\n",
    "        Title: {info['title']}\n",
    "        Authors: {', '.join(info['authors'])}\n",
    "        Published: {info['published']}\n",
    "        Summary: {info['summary']}\n",
    "        \"\"\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Please analyze these {len(papers_info)} research papers on the topic of \"{topic}\" and provide:\n",
    "\n",
    "    1. **Common Themes:** What are the main research themes and areas of focus?\n",
    "    2. **Methodological Approaches:** What different methodologies and techniques are being used?\n",
    "    3. **Research Gaps:** What gaps or opportunities for future research do you identify?\n",
    "    4. **Key Trends:** What trends do you notice in the research over time?\n",
    "    5. **Comparative Analysis:** How do these papers relate to each other? Are there complementary or competing approaches?\n",
    "    6. **Practical Applications:** What are the potential real-world applications of this research?\n",
    "\n",
    "    Papers Summary:\n",
    "    {\"\".join(papers_summary)}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.messages.create(\n",
    "            max_tokens=2500,\n",
    "            model='claude-3-5-sonnet-20241022',\n",
    "            messages=[{'role': 'user', 'content': prompt}]\n",
    "        )\n",
    "        \n",
    "        return response.content[0].text\n",
    "    except Exception as e:\n",
    "        return f\"Error analyzing papers: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70e68f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_summary_to_file(paper_id: str, summary_type: str = \"comprehensive\") -> str:\n",
    "    \"\"\"\n",
    "    Save paper summary to a text file\n",
    "    \n",
    "    Args:\n",
    "        paper_id: The ID of the paper to summarize and save\n",
    "        summary_type: Type of summary - \"comprehensive\" (full analysis) or \"basic\" (just paper info)\n",
    "    \n",
    "    Returns:\n",
    "        Status message about the save operation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create summaries directory if it doesn't exist\n",
    "        summaries_dir = \"summaries\"\n",
    "        os.makedirs(summaries_dir, exist_ok=True)\n",
    "        \n",
    "        # Get the summary based on type\n",
    "        if summary_type.lower() == \"comprehensive\":\n",
    "            summary_content = summarize_paper(paper_id)\n",
    "            if summary_content.startswith(\"Paper with ID\") or summary_content.startswith(\"Could not download\"):\n",
    "                return summary_content\n",
    "            file_suffix = \"_comprehensive_summary\"\n",
    "        elif summary_type.lower() == \"basic\":\n",
    "            summary_content = extract_info(paper_id)\n",
    "            if summary_content.startswith(\"Paper with ID\"):\n",
    "                return summary_content\n",
    "            file_suffix = \"_basic_info\"\n",
    "        else:\n",
    "            return \"Invalid summary_type. Use 'comprehensive' or 'basic'\"\n",
    "        \n",
    "        # Create filename\n",
    "        filename = f\"{paper_id}{file_suffix}.txt\"\n",
    "        file_path = os.path.join(summaries_dir, filename)\n",
    "        \n",
    "        # Add timestamp and metadata\n",
    "        from datetime import datetime\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        header = f\"\"\"\n",
    "================================================================================\n",
    "PAPER SUMMARY - {summary_type.upper()}\n",
    "================================================================================\n",
    "Paper ID: {paper_id}\n",
    "Generated: {timestamp}\n",
    "Summary Type: {summary_type.capitalize()}\n",
    "================================================================================\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        # Write to file\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(header)\n",
    "            f.write(summary_content)\n",
    "            f.write(f\"\\n\\n{'='*80}\\nEnd of Summary\\n{'='*80}\")\n",
    "        \n",
    "        return f\"Summary saved successfully to: {file_path}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error saving summary: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1dc7899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_topic_analysis_to_file(topic: str) -> str:\n",
    "    \"\"\"\n",
    "    Save topic analysis to a text file\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to analyze and save\n",
    "    \n",
    "    Returns:\n",
    "        Status message about the save operation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create summaries directory if it doesn't exist\n",
    "        summaries_dir = \"summaries\"\n",
    "        os.makedirs(summaries_dir, exist_ok=True)\n",
    "        \n",
    "        # Get the topic analysis\n",
    "        analysis_content = analyze_papers_by_topic(topic)\n",
    "        \n",
    "        if analysis_content.startswith(\"No papers found\"):\n",
    "            return analysis_content\n",
    "        \n",
    "        # Create filename\n",
    "        topic_safe = topic.lower().replace(' ', '_').replace('/', '_')\n",
    "        filename = f\"{topic_safe}_topic_analysis.txt\"\n",
    "        file_path = os.path.join(summaries_dir, filename)\n",
    "        \n",
    "        # Add timestamp and metadata\n",
    "        from datetime import datetime\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        header = f\"\"\"\n",
    "================================================================================\n",
    "TOPIC ANALYSIS REPORT\n",
    "================================================================================\n",
    "Topic: {topic}\n",
    "Generated: {timestamp}\n",
    "Analysis Type: Comparative Topic Analysis\n",
    "================================================================================\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        # Write to file\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(header)\n",
    "            f.write(analysis_content)\n",
    "            f.write(f\"\\n\\n{'='*80}\\nEnd of Analysis\\n{'='*80}\")\n",
    "        \n",
    "        return f\"Topic analysis saved successfully to: {file_path}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error saving topic analysis: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47f0d1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool Schema for the LLM\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"name\": \"search_papers\",\n",
    "        \"description\": \"Search for relevant papers on arxiv based on a topic\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"topic\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The topic to search for papers on arxiv\"\n",
    "                },\n",
    "                \"max_results\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Maximum number of results to return\",\n",
    "                    \"default\": 5\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"topic\"]\n",
    "        }   \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"extract_info\",\n",
    "        \"description\": \"Extract basic information about a paper by its ID\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"paper_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The ID of the paper to extract information for\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"paper_id\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"summarize_paper\",\n",
    "        \"description\": \"Get comprehensive summary of a paper including abstract, problem statement, methodology, existing solutions, improvements, results, and key findings\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"paper_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The ID of the paper to summarize\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"paper_id\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"analyze_papers_by_topic\",\n",
    "        \"description\": \"Analyze all papers in a topic directory and provide comparative insights including common themes, methodological approaches, research gaps, and trends\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"topic\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The topic to analyze papers for\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"topic\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"save_summary_to_file\",\n",
    "        \"description\": \"Save paper summary to a text file. Can save either comprehensive analysis or basic paper information\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"paper_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The ID of the paper to summarize and save\"\n",
    "                },\n",
    "                \"summary_type\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Type of summary to save: 'comprehensive' (full analysis) or 'basic' (just paper info)\",\n",
    "                    \"enum\": [\"comprehensive\", \"basic\"],\n",
    "                    \"default\": \"comprehensive\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"paper_id\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"save_topic_analysis_to_file\",\n",
    "        \"description\": \"Save topic analysis to a text file with comparative insights for all papers in a topic\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"topic\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The topic to analyze and save\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"topic\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a56fc205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool Mapping and execution\n",
    "\n",
    "mapping_tool_functions = {\n",
    "    \"search_papers\": search_paper,\n",
    "    \"extract_info\": extract_info,\n",
    "    \"summarize_paper\": summarize_paper,\n",
    "    \"analyze_papers_by_topic\": analyze_papers_by_topic,\n",
    "    \"save_summary_to_file\": save_summary_to_file,\n",
    "    \"save_topic_analysis_to_file\": save_topic_analysis_to_file\n",
    "}\n",
    "\n",
    "def execute_tool(tool_name: str, tool_args):\n",
    "    result = mapping_tool_functions[tool_name](**tool_args)\n",
    "    if result is None:\n",
    "        result = \"Completed successfully, but no result returned.\"\n",
    "    elif isinstance(result, list):\n",
    "        result = \", \".join(result)\n",
    "    elif isinstance(result, dict):\n",
    "        result = json.dumps(result, indent=2)\n",
    "    else:\n",
    "        result = str(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77f44f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANTHROPIC_API_KEY = \"\" # Replace with your actual API key or create a .env file with the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "297739cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() \n",
    "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6dc1341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nresponse = client.messages.create(max_tokens = 500,\\n                                  model = \\'claude-opus-4-20250514\\', \\n                                    temperature=1,\\n                                  system=\"You are a world class poet. Respond only with poems.\",\\n                                  messages = [{\\'role\\': \\'user\\', \\'content\\': [{\"type\":\"text\",\\n                                                                            \"text\": \"Why is the ocean salty?\"}]}])\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "response = client.messages.create(max_tokens = 500,\n",
    "                                  model = 'claude-opus-4-20250514', \n",
    "                                    temperature=1,\n",
    "                                  system=\"You are a world class poet. Respond only with poems.\",\n",
    "                                  messages = [{'role': 'user', 'content': [{\"type\":\"text\",\n",
    "                                                                            \"text\": \"Why is the ocean salty?\"}]}])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ee38450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4dd82799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Querry Looop\n",
    "\n",
    "def process_query(query):\n",
    "    \n",
    "    messages = [{'role': 'user', 'content': query}]\n",
    "    \n",
    "    response = client.messages.create(max_tokens = 2024,\n",
    "                                  model = 'claude-3-7-sonnet-20250219', \n",
    "                                  tools = tools,\n",
    "                                  messages = messages)\n",
    "    \n",
    "    process_query = True\n",
    "    while process_query:\n",
    "        assistant_content = []\n",
    "\n",
    "        for content in response.content:\n",
    "            if content.type == 'text':\n",
    "                \n",
    "                print(content.text)\n",
    "                assistant_content.append(content)\n",
    "                \n",
    "                if len(response.content) == 1:\n",
    "                    process_query = False\n",
    "            \n",
    "            elif content.type == 'tool_use':\n",
    "                \n",
    "                assistant_content.append(content)\n",
    "                messages.append({'role': 'assistant', 'content': assistant_content})\n",
    "                \n",
    "                tool_id = content.id\n",
    "                tool_args = content.input\n",
    "                tool_name = content.name\n",
    "                print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "                \n",
    "                result = execute_tool(tool_name, tool_args)\n",
    "                messages.append({\"role\": \"user\", \n",
    "                                  \"content\": [\n",
    "                                      {\n",
    "                                          \"type\": \"tool_result\",\n",
    "                                          \"tool_use_id\": tool_id,\n",
    "                                          \"content\": result\n",
    "                                      }\n",
    "                                  ]\n",
    "                                })\n",
    "                response = client.messages.create(max_tokens = 2024,\n",
    "                                  model = 'claude-3-7-sonnet-20250219', \n",
    "                                  tools = tools,\n",
    "                                  messages = messages) \n",
    "                \n",
    "                if len(response.content) == 1 and response.content[0].type == \"text\":\n",
    "                    print(response.content[0].text)\n",
    "                    process_query = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8b2c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat Loop\n",
    "\n",
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "    \n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a694a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n",
      "I'll search for the latest papers on generative machine learning for you. Let me retrieve that information.\n",
      "Calling tool search_papers with args {'topic': 'generative machine learning', 'max_results': 5}\n",
      "I'll search for the latest papers on generative machine learning for you. Let me retrieve that information.\n",
      "Calling tool search_papers with args {'topic': 'generative machine learning', 'max_results': 5}\n",
      "Saved paper info to: papers\\generative_machine_learning\\papers_info.json\n",
      "Saved paper info to: papers\\generative_machine_learning\\papers_info.json\n",
      "I've found the 5 most relevant papers on generative machine learning. Let me provide you with the basic information about each of them:\n",
      "Calling tool extract_info with args {'paper_id': '2001.04942v2'}\n",
      "I've found the 5 most relevant papers on generative machine learning. Let me provide you with the basic information about each of them:\n",
      "Calling tool extract_info with args {'paper_id': '2001.04942v2'}\n",
      "Calling tool extract_info with args {'paper_id': '2204.07492v2'}\n",
      "Calling tool extract_info with args {'paper_id': '2204.07492v2'}\n",
      "Calling tool extract_info with args {'paper_id': '1811.06622v1'}\n",
      "Calling tool extract_info with args {'paper_id': '1811.06622v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2006.15680v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2006.15680v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2110.12773v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2110.12773v1'}\n",
      "Here are the 5 papers on generative machine learning I found:\n",
      "\n",
      "1. **Private Machine Learning via Randomised Response** (Jan 2020)\n",
      "   - Author: David Barber\n",
      "   - Focuses on a framework for private machine learning using randomised response, designed to protect data privacy while still allowing model training.\n",
      "\n",
      "2. **A Machine Learning Tutorial for Operational Meteorology, Part I: Traditional Machine Learning** (Apr 2022)\n",
      "   - Authors: Randy J. Chase, David R. Harrison, Amanda Burke, et al.\n",
      "   - A tutorial on machine learning methods for meteorology, covering several techniques with practical examples.\n",
      "\n",
      "3. **Concept-Oriented Deep Learning: Generative Concept Representations** (Nov 2018)\n",
      "   - Author: Daniel T. Chang\n",
      "   - Discusses generative concept representations and their advantages over discriminative ones, specifically exploring variational autoencoders and generative adversarial networks.\n",
      "\n",
      "4. **Modeling Generalization in Machine Learning: A Methodological and Computational Study** (Jun 2020)\n",
      "   - Authors: Pietro Barbiero, Giovanni Squillero, Alberto Tonda\n",
      "   - Analyzes how machine learning algorithms generalize to unseen data across 109 datasets, challenging some common assumptions about dimensionality.\n",
      "\n",
      "5. **Scientific Machine Learning Benchmarks** (Oct 2021)\n",
      "   - Authors: Jeyan Thiyagalingam, Mallikarjun Shankar, Geoffrey Fox, Tony Hey\n",
      "   - Discusses benchmarking approaches for scientific machine learning, addressing the challenges scientists face when selecting appropriate ML algorithms.\n",
      "\n",
      "The third paper specifically focuses on generative models, while the others address broader machine learning topics including generalization, privacy, and benchmarking which relate to generative machine learning. Would you like me to provide a more detailed summary of any of these papers?\n",
      "\n",
      "\n",
      "Here are the 5 papers on generative machine learning I found:\n",
      "\n",
      "1. **Private Machine Learning via Randomised Response** (Jan 2020)\n",
      "   - Author: David Barber\n",
      "   - Focuses on a framework for private machine learning using randomised response, designed to protect data privacy while still allowing model training.\n",
      "\n",
      "2. **A Machine Learning Tutorial for Operational Meteorology, Part I: Traditional Machine Learning** (Apr 2022)\n",
      "   - Authors: Randy J. Chase, David R. Harrison, Amanda Burke, et al.\n",
      "   - A tutorial on machine learning methods for meteorology, covering several techniques with practical examples.\n",
      "\n",
      "3. **Concept-Oriented Deep Learning: Generative Concept Representations** (Nov 2018)\n",
      "   - Author: Daniel T. Chang\n",
      "   - Discusses generative concept representations and their advantages over discriminative ones, specifically exploring variational autoencoders and generative adversarial networks.\n",
      "\n",
      "4. **Modeling Generalization in Machine Learning: A Methodological and Computational Study** (Jun 2020)\n",
      "   - Authors: Pietro Barbiero, Giovanni Squillero, Alberto Tonda\n",
      "   - Analyzes how machine learning algorithms generalize to unseen data across 109 datasets, challenging some common assumptions about dimensionality.\n",
      "\n",
      "5. **Scientific Machine Learning Benchmarks** (Oct 2021)\n",
      "   - Authors: Jeyan Thiyagalingam, Mallikarjun Shankar, Geoffrey Fox, Tony Hey\n",
      "   - Discusses benchmarking approaches for scientific machine learning, addressing the challenges scientists face when selecting appropriate ML algorithms.\n",
      "\n",
      "The third paper specifically focuses on generative models, while the others address broader machine learning topics including generalization, privacy, and benchmarking which relate to generative machine learning. Would you like me to provide a more detailed summary of any of these papers?\n",
      "\n",
      "\n",
      "I need a bit more information to help you retrieve a summary. To get a paper summary, I need to know:\n",
      "\n",
      "1. Which specific paper (by paper ID) you want to summarize, or\n",
      "2. The topic you're interested in so I can search for papers first\n",
      "\n",
      "If you've already searched for papers on a topic but didn't mention which one, please let me know the topic so I can search and identify the 3rd paper from the results. Alternatively, if you have a specific paper ID, please share that with me.\n",
      "\n",
      "\n",
      "I need a bit more information to help you retrieve a summary. To get a paper summary, I need to know:\n",
      "\n",
      "1. Which specific paper (by paper ID) you want to summarize, or\n",
      "2. The topic you're interested in so I can search for papers first\n",
      "\n",
      "If you've already searched for papers on a topic but didn't mention which one, please let me know the topic so I can search and identify the 3rd paper from the results. Alternatively, if you have a specific paper ID, please share that with me.\n",
      "\n",
      "\n",
      "I can help you summarize that paper. Let me search for and retrieve information about paper 1811.06622v1.\n",
      "Calling tool extract_info with args {'paper_id': '1811.06622v1'}\n",
      "I can help you summarize that paper. Let me search for and retrieve information about paper 1811.06622v1.\n",
      "Calling tool extract_info with args {'paper_id': '1811.06622v1'}\n",
      "Now that I have the basic information, let me get a comprehensive summary of this paper for you:\n",
      "Calling tool summarize_paper with args {'paper_id': '1811.06622v1'}\n",
      "Now that I have the basic information, let me get a comprehensive summary of this paper for you:\n",
      "Calling tool summarize_paper with args {'paper_id': '1811.06622v1'}\n",
      "# Summary of \"Concept-Oriented Deep Learning: Generative Concept Representations\"\n",
      "\n",
      "## Paper Overview\n",
      "This 2018 paper by Daniel T. Chang introduces generative concept representations as an extension to concept-oriented deep learning (CODL). The paper proposes theoretical frameworks rather than presenting experimental results.\n",
      "\n",
      "## Key Advantages of Generative Concept Representations\n",
      "The author identifies three major advantages over discriminative representations:\n",
      "1. **Uncertainty Representation**: Better handling of uncertainty in data and models\n",
      "2. **Integration of Learning and Reasoning**: Combines deep learning with reasoning capabilities\n",
      "3. **Improved Unsupervised Learning**: More effective for unsupervised and semi-supervised learning scenarios\n",
      "\n",
      "## Technical Approach\n",
      "The paper proposes using:\n",
      "- Probabilistic Graphical Models (PGMs)\n",
      "- Deep Generative Models (DGMs)\n",
      "- Two main implementation approaches:\n",
      "  - Variational autoencoders (VAEs)\n",
      "  - Generative adversarial networks (GANs)\n",
      "\n",
      "## Problem Being Addressed\n",
      "The research addresses several limitations in traditional deep learning:\n",
      "- Poor uncertainty representation\n",
      "- Disconnect between learning and reasoning capabilities\n",
      "- Over-reliance on labeled data\n",
      "- Difficulties with high-dimensional variables in unsupervised learning\n",
      "\n",
      "## Limitations\n",
      "The paper acknowledges challenges including:\n",
      "- Computational complexity in high-dimensional calculations\n",
      "- Statistical challenges in generalization\n",
      "- Difficulty interpreting latent variables\n",
      "- Optimization challenges with intractable criteria\n",
      "\n",
      "This paper appears to be primarily theoretical, establishing a conceptual framework rather than providing empirical validation of the approaches.\n",
      "\n",
      "Would you like me to save a more comprehensive summary of this paper to a file?\n",
      "\n",
      "\n",
      "# Summary of \"Concept-Oriented Deep Learning: Generative Concept Representations\"\n",
      "\n",
      "## Paper Overview\n",
      "This 2018 paper by Daniel T. Chang introduces generative concept representations as an extension to concept-oriented deep learning (CODL). The paper proposes theoretical frameworks rather than presenting experimental results.\n",
      "\n",
      "## Key Advantages of Generative Concept Representations\n",
      "The author identifies three major advantages over discriminative representations:\n",
      "1. **Uncertainty Representation**: Better handling of uncertainty in data and models\n",
      "2. **Integration of Learning and Reasoning**: Combines deep learning with reasoning capabilities\n",
      "3. **Improved Unsupervised Learning**: More effective for unsupervised and semi-supervised learning scenarios\n",
      "\n",
      "## Technical Approach\n",
      "The paper proposes using:\n",
      "- Probabilistic Graphical Models (PGMs)\n",
      "- Deep Generative Models (DGMs)\n",
      "- Two main implementation approaches:\n",
      "  - Variational autoencoders (VAEs)\n",
      "  - Generative adversarial networks (GANs)\n",
      "\n",
      "## Problem Being Addressed\n",
      "The research addresses several limitations in traditional deep learning:\n",
      "- Poor uncertainty representation\n",
      "- Disconnect between learning and reasoning capabilities\n",
      "- Over-reliance on labeled data\n",
      "- Difficulties with high-dimensional variables in unsupervised learning\n",
      "\n",
      "## Limitations\n",
      "The paper acknowledges challenges including:\n",
      "- Computational complexity in high-dimensional calculations\n",
      "- Statistical challenges in generalization\n",
      "- Difficulty interpreting latent variables\n",
      "- Optimization challenges with intractable criteria\n",
      "\n",
      "This paper appears to be primarily theoretical, establishing a conceptual framework rather than providing empirical validation of the approaches.\n",
      "\n",
      "Would you like me to save a more comprehensive summary of this paper to a file?\n",
      "\n",
      "\n",
      "I'd be happy to help, but I need more information about what you're looking for. Would you like me to:\n",
      "\n",
      "1. Search for papers on a specific topic?\n",
      "2. Get information about a particular paper?\n",
      "3. Analyze papers in a certain research area?\n",
      "\n",
      "Could you please provide more details about what you're interested in, such as a specific research topic, paper ID, or area of study you'd like to explore?\n",
      "\n",
      "\n",
      "I'd be happy to help, but I need more information about what you're looking for. Would you like me to:\n",
      "\n",
      "1. Search for papers on a specific topic?\n",
      "2. Get information about a particular paper?\n",
      "3. Analyze papers in a certain research area?\n",
      "\n",
      "Could you please provide more details about what you're interested in, such as a specific research topic, paper ID, or area of study you'd like to explore?\n",
      "\n",
      "\n",
      "I'd be happy to help you save a paper summary to a file. However, I need a few more details:\n",
      "\n",
      "1. Which paper would you like to summarize? I'll need the paper ID to generate the summary.\n",
      "2. Would you prefer a comprehensive summary or just basic information about the paper?\n",
      "\n",
      "Once you provide the paper ID, I can save either a comprehensive or basic summary to a file for you. If you haven't searched for a paper yet, I can help you search for relevant papers on a topic of your choice first.\n",
      "\n",
      "\n",
      "I'd be happy to help you save a paper summary to a file. However, I need a few more details:\n",
      "\n",
      "1. Which paper would you like to summarize? I'll need the paper ID to generate the summary.\n",
      "2. Would you prefer a comprehensive summary or just basic information about the paper?\n",
      "\n",
      "Once you provide the paper ID, I can save either a comprehensive or basic summary to a file for you. If you haven't searched for a paper yet, I can help you search for relevant papers on a topic of your choice first.\n",
      "\n",
      "\n",
      "I'll help you save the summary of paper 1811.06622v1 to a file. Let me do that for you right away.\n",
      "Calling tool save_summary_to_file with args {'paper_id': '1811.06622v1'}\n",
      "I'll help you save the summary of paper 1811.06622v1 to a file. Let me do that for you right away.\n",
      "Calling tool save_summary_to_file with args {'paper_id': '1811.06622v1'}\n",
      "I've successfully saved a comprehensive summary of paper 1811.06622v1 to a file. The summary has been stored at: \"summaries\\1811.06622v1_comprehensive_summary.txt\"\n",
      "\n",
      "This file contains a detailed analysis of the paper including its abstract, problem statement, methodology, existing solutions, improvements, results, and key findings. You can access this file to review the complete summary whenever needed.\n",
      "\n",
      "\n",
      "I've successfully saved a comprehensive summary of paper 1811.06622v1 to a file. The summary has been stored at: \"summaries\\1811.06622v1_comprehensive_summary.txt\"\n",
      "\n",
      "This file contains a detailed analysis of the paper including its abstract, problem statement, methodology, existing solutions, improvements, results, and key findings. You can access this file to review the complete summary whenever needed.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "997a8ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available tools:\n",
      "- search_papers: Search for relevant papers on arxiv based on a topic\n",
      "- extract_info: Extract basic information about a paper by its ID\n",
      "- summarize_paper: Get comprehensive summary of a paper including abstract, problem statement, methodology, existing solutions, improvements, results, and key findings\n",
      "- analyze_papers_by_topic: Analyze all papers in a topic directory and provide comparative insights including common themes, methodological approaches, research gaps, and trends\n",
      "- save_summary_to_file: Save paper summary to a text file. Can save either comprehensive analysis or basic paper information\n",
      "- save_topic_analysis_to_file: Save topic analysis to a text file with comparative insights for all papers in a topic\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAvailable tools:\")\n",
    "for tool in tools:\n",
    "    print(f\"- {tool['name']}: {tool['description']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
